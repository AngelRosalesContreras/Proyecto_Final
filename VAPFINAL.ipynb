{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AngelRosalesContreras/Proyecto_Final/blob/main/VAPFINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wDR3fzdXhBr"
      },
      "source": [
        "# Flujo óptico denso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ha34R_CDXeKG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "3e6860a4-fc2b-4d55-dfa6-4bd90cb5ef5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.18 FPS\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "DisabledFunctionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDisabledFunctionError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-42c52778912c>\u001b[0m in \u001b[0;36m<cell line: 219>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{fps:.2f} FPS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Flow\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdraw_flow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HSV\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdraw_hsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_import_hooks/_cv2.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mDisabledFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDisabledFunctionError\u001b[0m: cv2.imshow() is disabled in Colab, because it causes Jupyter sessions\nto crash; see https://github.com/jupyter/notebook/issues/3935.\nAs a substitution, consider using\n  from google.colab.patches import cv2_imshow\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_snippet",
                "actionText": "Search Snippets for cv2.imshow",
                "snippetFilter": "cv2.imshow"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import time\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Diccionario para almacenar colores únicos por clúster\n",
        "cluster_colors = {}\n",
        "\n",
        "def get_random_color(cluster):\n",
        "    # Verificar si ya se asignó un color para este clúster\n",
        "    if cluster not in cluster_colors:\n",
        "        # Si no se ha asignado, generar un color aleatorio\n",
        "        cluster_colors[cluster] = tuple(map(int, np.random.randint(0, 256, 3)))\n",
        "    return cluster_colors[cluster]\n",
        "\n",
        "def elbow_method(data, max_clusters=10):\n",
        "    distortions = []\n",
        "    n_samples = len(data)\n",
        "\n",
        "    for i in range(1, min(max_clusters, n_samples) + 1):\n",
        "        kmeans = KMeans(n_clusters=i, random_state=0)\n",
        "        kmeans.fit(data)\n",
        "        distortions.append(kmeans.inertia_)\n",
        "\n",
        "    # Calcular la derivada segunda de la curva de distorsión\n",
        "    acceleration = np.diff(np.diff(distortions))\n",
        "\n",
        "    # Encontrar el índice donde la aceleración es máxima\n",
        "    optimal_k_index = np.argmax(acceleration) + 2  # Sumar 2 para compensar la doble diferenciación\n",
        "\n",
        "    # Graficar la curva de distorsión y resaltar el punto óptimo\n",
        "    plt.plot(range(1, min(max_clusters, n_samples) + 1), distortions, marker='o')\n",
        "    plt.scatter(optimal_k_index, distortions[optimal_k_index - 1], c='red', label='Optimal k')\n",
        "    plt.title('Elbow Method for Optimal k')\n",
        "    plt.xlabel('Number of Clusters')\n",
        "    plt.ylabel('Distortion')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Devolver el número óptimo de clústeres\n",
        "    return optimal_k_index\n",
        "\n",
        "\n",
        "def apply_kmeans_to_freeman_list(img,contours,freeman_chaincodes):\n",
        "    if not freeman_chaincodes:\n",
        "        print(\"No hay datos para aplicar K-Means.\")\n",
        "        return []\n",
        "\n",
        "    # Obtener características de las cadenas de Freeman\n",
        "    def get_freeman_features(chain_code):\n",
        "        length = len(chain_code)\n",
        "        direction_changes = sum(1 for a, b in zip(chain_code, chain_code[1:]) if a != b)\n",
        "        return length, direction_changes\n",
        "\n",
        "    # Obtener características para cada cadena de Freeman\n",
        "    features = [get_freeman_features(chain_code) for chain_code in freeman_chaincodes]\n",
        "    features_array = np.array(features)\n",
        "\n",
        "    if features_array.ndim == 1:\n",
        "        # Si es un array 1D, redimensiona a 2D\n",
        "        features_array = features_array.reshape(-1, 1)\n",
        "\n",
        "    # Aplicar el método del codo para determinar el número óptimo de clústeres\n",
        "    optimal_k = elbow_method(features_array,max_clusters=10)\n",
        "    print(optimal_k)\n",
        "\n",
        "    # Aplicar k-medias con el número óptimo de clústeres\n",
        "    kmeans = KMeans(n_clusters=optimal_k, random_state=0)\n",
        "    kmeans.fit(features_array)\n",
        "\n",
        "    # Obtener etiquetas para cada cadena de Freeman\n",
        "    labels = kmeans.labels_\n",
        "\n",
        "    # Visualizar en un gráfico de dispersión\n",
        "    lengths, changes = zip(*[get_freeman_features(chain_code) for chain_code in freeman_chaincodes])\n",
        "    plt.scatter(lengths, changes, c=labels, cmap='viridis', marker='o', edgecolors='k', label='Data Points')\n",
        "    plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c='red', marker='x', s=200,\n",
        "                label='Centroids')\n",
        "    plt.title('K-Means Clustering of Freeman Chain Codes with Centroids')\n",
        "    plt.xlabel('Length of Chain Code')\n",
        "    plt.ylabel('Number of Direction Changes')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Crear una imagen para visualizar elementos de cada clúster en el frame\n",
        "    clustered_frame = img.copy()\n",
        "\n",
        "    # Encontrar contornos en la máscara\n",
        "    # contours, _ = cv2.findContours(motion_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    for i, contour in enumerate(contours):\n",
        "        cluster_color = get_random_color(labels[i])\n",
        "        cv2.drawContours(clustered_frame, [contour], -1, (0, 255, 0), 2)\n",
        "        # Asignar un color específico para cada clúster\n",
        "        # color = tuple(map(int, plt.cm.viridis(labels[i] / optimal_k)[:3] * 255))\n",
        "        cv2.drawContours(clustered_frame, [contour], -1,  cluster_color, -1)  # Rellenar el contorno con el color del clúster\n",
        "\n",
        "    cv2.imshow(\"Clustered Objects\", clustered_frame)\n",
        "    cv2.waitKey(0)  # Esperar hasta que se presione una tecla para cerrar la ventana\n",
        "\n",
        "    return labels\n",
        "\n",
        "\n",
        "\n",
        "def draw_flow(img, flow, step=16):\n",
        "    h, w = img.shape[:2]\n",
        "    y, x = np.mgrid[step/2:h:step, step/2:w:step].reshape(2, -1).astype(int)\n",
        "    fx, fy = flow[y, x].T\n",
        "    lines = np.vstack([x, y, x - fx, y - fy]).T.reshape(-1, 2, 2)\n",
        "    lines = np.int32(lines + 0.5)\n",
        "    img_bgr = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "    cv2.polylines(img_bgr, lines, 0, (0, 255, 0))\n",
        "    for (x1, y1), (_x2, _y2) in lines:\n",
        "        cv2.circle(img_bgr, (x1, y1), 1, (0, 255, 0), -1)\n",
        "\n",
        "    return img_bgr\n",
        "\n",
        "\n",
        "def draw_hsv(flow):\n",
        "    h, w = flow.shape[:2]\n",
        "    fx, fy = flow[:,:,0], flow[:,:,1]\n",
        "    ang = np.arctan2(fy, fx) + np.pi\n",
        "    v = np.sqrt(fx*fx+fy*fy)\n",
        "    hsv = np.zeros((h, w, 3), np.uint8)\n",
        "    hsv[...,0] = ang * (180/np.pi/2)\n",
        "    hsv[...,1] = 255\n",
        "    hsv[...,2] = np.minimum(v * 4, 255)\n",
        "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "    return bgr\n",
        "\n",
        "\n",
        "def get_freeman_chaincode(contour):\n",
        "    chain_code = []\n",
        "    direction_map = [0, 1, 2, 3, 4, 5, 6, 7]\n",
        "\n",
        "    for i in range(1, len(contour)):\n",
        "        delta_x = contour[i][0][0] - contour[i - 1][0][0]\n",
        "        delta_y = contour[i][0][1] - contour[i - 1][0][1]\n",
        "\n",
        "        # Determinar la dirección del movimiento\n",
        "        direction = (delta_x > 0) + (delta_y > 0) * 2 + (delta_x < 0) * 4 + (delta_y < 0) * 6\n",
        "\n",
        "        try:\n",
        "            chain_code.append(direction_map.index(direction))\n",
        "        except ValueError:\n",
        "            # Si la dirección no está en la lista, manejar la excepción\n",
        "            pass\n",
        "\n",
        "    return chain_code\n",
        "\n",
        "def extract_freeman_from_contours(contours):\n",
        "    freeman_chaincodes = []\n",
        "\n",
        "    for contour in contours:\n",
        "        freeman_chaincode = get_freeman_chaincode(contour)\n",
        "        freeman_chaincodes.append(freeman_chaincode)\n",
        "\n",
        "    return freeman_chaincodes\n",
        "\n",
        "def draw_contours_on_image(image, contours):\n",
        "    image_with_contours = image.copy()\n",
        "    cv2.drawContours(image_with_contours, contours, -1, (0, 255, 0), 2)\n",
        "    return image_with_contours\n",
        "\n",
        "def segment_objects_with_optical_flow(frame, flow, threshold=1.0):\n",
        "    # Obtener la magnitud del flujo óptico\n",
        "    magnitude = np.sqrt(flow[..., 0] ** 2 + flow[..., 1] ** 2)\n",
        "\n",
        "    # Aplicar umbralización para resaltar las áreas de cambio\n",
        "    motion_mask = (magnitude > threshold).astype(np.uint8) * 255\n",
        "\n",
        "    # Aplicar filtros morfológicos para mejorar la máscara\n",
        "    kernel = np.ones((5, 5), np.uint8)\n",
        "    motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_OPEN, kernel)\n",
        "    motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    # Crear una imagen en blanco\n",
        "    blue_background = np.zeros_like(frame)\n",
        "    # Asignar color azul a las áreas de cambio\n",
        "    blue_background[motion_mask > 0] = (255, 0, 0)\n",
        "\n",
        "    # Combinar la imagen original con el fondo azul\n",
        "    segmented_objects = cv2.addWeighted(frame, 1, blue_background, 0.5, 0)\n",
        "\n",
        "    # Crear una imagen en blanco para la ROI\n",
        "    frame_with_freeman = frame.copy()\n",
        "\n",
        "    # Encontrar contornos en la máscara\n",
        "    contours, _ = cv2.findContours(motion_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Dibujar los contornos en la ROI\n",
        "    # Listas para almacenar las cadenas de Freeman\n",
        "    all_freeman_chaincodes = []\n",
        "\n",
        "    for contour in contours:\n",
        "        cv2.drawContours(frame_with_freeman, [contour], -1, (0, 255, 0), 2)\n",
        "\n",
        "        # Obtener la cadena de contornos de Freeman\n",
        "        freeman_chaincode = get_freeman_chaincode(contour)\n",
        "\n",
        "        cv2.imshow(\"Freeman Contour\", frame_with_freeman)\n",
        "        all_freeman_chaincodes.append(freeman_chaincode)\n",
        "\n",
        "        # print(\"Freeman Chain Code:\", freeman_chaincode)\n",
        "    print(\"Freeman Chain Code:\", all_freeman_chaincodes)\n",
        "    kmeans_labels = apply_kmeans_to_freeman_list(frame,contours, all_freeman_chaincodes)\n",
        "    print(\"K-Means Labels:\", kmeans_labels)\n",
        "\n",
        "    return segmented_objects\n",
        "\n",
        "# Código principal aquí\n",
        "video_path = 'car.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "suc, prev = cap.read()\n",
        "prevgray = cv2.cvtColor(prev, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "while True:\n",
        "    suc, img = cap.read()\n",
        "    if not suc:\n",
        "        break  # Si no se puede leer el siguiente cuadro, sal del bucle\n",
        "\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Iniciar el tiempo para calcular el FPS\n",
        "    start = time.time()\n",
        "\n",
        "    # Calcular el flujo óptico\n",
        "    flow = cv2.calcOpticalFlowFarneback(prevgray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "\n",
        "    prevgray = gray\n",
        "\n",
        "    end = time.time()\n",
        "    # Calcular el FPS para la detección del cuadro actual\n",
        "    fps = 1 / (end - start)\n",
        "\n",
        "    print(f\"{fps:.2f} FPS\")\n",
        "\n",
        "    cv2.imshow(\"Flow\", draw_flow(gray, flow))\n",
        "    cv2.imshow(\"HSV\", draw_hsv(flow))\n",
        "\n",
        "    # Segmentar objetos en movimiento y marcarlos en color azul\n",
        "    segmented_objects = segment_objects_with_optical_flow(img, flow)\n",
        "\n",
        "    cv2.imshow(\"Segmented Objects\", segmented_objects)\n",
        "\n",
        "    key = cv2.waitKey(5)\n",
        "    if key == ord('q'):\n",
        "        break\n",
        "\n",
        "    # Agregar una pausa para limitar la velocidad de procesamiento a 2 FPS\n",
        "    time.sleep(1)\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FH-ZvcnMzNIU"
      },
      "source": [
        "# Flujo óptico disperso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdnoEeifzP9D"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import time\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Diccionario para almacenar colores únicos por clúster\n",
        "cluster_colors = {}\n",
        "\n",
        "def get_random_color(cluster):\n",
        "    # Verificar si ya se asignó un color para este clúster\n",
        "    if cluster not in cluster_colors:\n",
        "        # Si no se ha asignado, generar un color aleatorio\n",
        "        cluster_colors[cluster] = tuple(map(int, np.random.randint(0, 256, 3)))\n",
        "    return cluster_colors[cluster]\n",
        "\n",
        "def elbow_method(data, max_clusters=10):\n",
        "    distortions = []\n",
        "    n_samples = len(data)\n",
        "\n",
        "    for i in range(1, min(max_clusters, n_samples) + 1):\n",
        "        kmeans = KMeans(n_clusters=i, random_state=0)\n",
        "        kmeans.fit(data)\n",
        "        distortions.append(kmeans.inertia_)\n",
        "\n",
        "    # Calcular la derivada segunda de la curva de distorsión\n",
        "    acceleration = np.diff(np.diff(distortions))\n",
        "\n",
        "    # Encontrar el índice donde la aceleración es máxima\n",
        "    optimal_k_index = np.argmax(acceleration) + 2  # Sumar 2 para compensar la doble diferenciación\n",
        "\n",
        "    # Graficar la curva de distorsión y resaltar el punto óptimo\n",
        "    plt.plot(range(1, min(max_clusters, n_samples) + 1), distortions, marker='o')\n",
        "    plt.scatter(optimal_k_index, distortions[optimal_k_index - 1], c='red', label='Optimal k')\n",
        "    plt.title('Elbow Method for Optimal k')\n",
        "    plt.xlabel('Number of Clusters')\n",
        "    plt.ylabel('Distortion')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Devolver el número óptimo de clústeres\n",
        "    return optimal_k_index\n",
        "\n",
        "def apply_kmeans_to_freeman_list(img, contours, freeman_chaincodes,roi_x, roi_y):\n",
        "    if not freeman_chaincodes:\n",
        "        print(\"No hay datos para aplicar K-Means.\")\n",
        "        return []\n",
        "\n",
        "    # Obtener características de las cadenas de Freeman\n",
        "    def get_freeman_features(chain_code):\n",
        "        length = len(chain_code)\n",
        "        direction_changes = sum(1 for a, b in zip(chain_code, chain_code[1:]) if a != b)\n",
        "        return length, direction_changes\n",
        "\n",
        "    # Obtener características para cada cadena de Freeman\n",
        "    features = [get_freeman_features(chain_code) for chain_code in freeman_chaincodes]\n",
        "    features_array = np.array(features)\n",
        "\n",
        "    if features_array.ndim == 1:\n",
        "        # Si es un array 1D, redimensiona a 2D\n",
        "        features_array = features_array.reshape(-1, 1)\n",
        "\n",
        "    # Aplicar el método del codo para determinar el número óptimo de clústeres\n",
        "    optimal_k = elbow_method(features_array, max_clusters=10)\n",
        "    print(optimal_k)\n",
        "\n",
        "    # Aplicar k-medias con el número óptimo de clústeres\n",
        "    kmeans = KMeans(n_clusters=optimal_k, random_state=0)\n",
        "    kmeans.fit(features_array)\n",
        "\n",
        "    # Obtener etiquetas para cada cadena de Freeman\n",
        "    labels = kmeans.labels_\n",
        "\n",
        "    # Visualizar en un gráfico de dispersión\n",
        "    lengths, changes = zip(*[get_freeman_features(chain_code) for chain_code in freeman_chaincodes])\n",
        "    plt.scatter(lengths, changes, c=labels, cmap='viridis', marker='o', edgecolors='k', label='Data Points')\n",
        "    plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c='red', marker='x', s=200,\n",
        "                label='Centroids')\n",
        "    plt.title('K-Means Clustering of Freeman Chain Codes with Centroids')\n",
        "    plt.xlabel('Length of Chain Code')\n",
        "    plt.ylabel('Number of Direction Changes')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Crear una imagen para visualizar elementos de cada clúster en el frame\n",
        "    clustered_frame = img.copy()\n",
        "\n",
        "    # Encontrar contornos en la máscara\n",
        "    for i, contour in enumerate(contours):\n",
        "        cluster_color = get_random_color(labels[i])\n",
        "        cv2.drawContours(clustered_frame, [contour], -1, (0, 255, 0), 2, offset=(roi_x, roi_y))\n",
        "        cv2.drawContours(clustered_frame, [contour], -1, cluster_color, -1, offset=(roi_x, roi_y))\n",
        "\n",
        "\n",
        "    img_resized = cv2.resize(clustered_frame, (width, height))\n",
        "    cv2.imshow(\"Clustered Objects\",img_resized )\n",
        "    cv2.waitKey(0)  # Esperar hasta que se presione una tecla para cerrar la ventana\n",
        "\n",
        "    return labels\n",
        "\n",
        "def initialize_params():\n",
        "    lk_params = dict(winSize=(30, 30),\n",
        "                 maxLevel=5,\n",
        "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 15, 0.01))\n",
        "\n",
        "    feature_params = dict(maxCorners=100,\n",
        "                      qualityLevel=0.01,\n",
        "                      minDistance=10,\n",
        "                      blockSize=7)\n",
        "    return lk_params, feature_params\n",
        "\n",
        "def process_roi(frame, trajectories, min_contour_area, max_contour_area, contours_dict, img):\n",
        "    if len(trajectories) > 0:\n",
        "        all_points = np.concatenate([np.int32(trajectory) for trajectory in trajectories])\n",
        "        x, y, w, h = cv2.boundingRect(all_points)\n",
        "\n",
        "        if 0 <= y < frame.shape[0] and 0 <= x < frame.shape[1] and h > 0 and w > 0:\n",
        "            roi = frame[y:y + h, x:x + w]\n",
        "            roi_x, roi_y = x, y  # Agrega estas líneas\n",
        "\n",
        "            if roi.size != 0:\n",
        "                roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
        "                _, thresh = cv2.threshold(roi_gray, 127, 255, 0)\n",
        "                contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "                contourss, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "                filtered_contours = [cnt for cnt in contours if min_contour_area < cv2.contourArea(cnt) < max_contour_area]\n",
        "\n",
        "                for trajectory in trajectories:\n",
        "                    for x, y in np.int32(trajectory):\n",
        "                        # Dibujar punto\n",
        "                        cv2.circle(img, (x, y), 1, (255, 0, 255), -1)\n",
        "\n",
        "                for contour in filtered_contours:\n",
        "                    # No agregar x e y aquí\n",
        "                    x, y, w, h = cv2.boundingRect(contour)\n",
        "                    cv2.rectangle(img, (x + roi_x, y + roi_y), (x + w + roi_x, y + h + roi_y), (255, 0, 0), 2)\n",
        "\n",
        "                    contour_id = id(contour)\n",
        "\n",
        "                    if contour_id not in contours_dict:\n",
        "                        color = tuple(np.random.randint(0, 255, 3).tolist())\n",
        "                        contours_dict[contour_id] = color\n",
        "                    else:\n",
        "                        color = contours_dict[contour_id]\n",
        "\n",
        "                    # No agregar x e y aquí\n",
        "                    cv2.drawContours(img, [contour + (roi_x, roi_y)], -1, color, 2)\n",
        "\n",
        "                all_freeman_chaincodes = extract_freeman_from_contours(contourss)\n",
        "                kmeans_labels = apply_kmeans_to_freeman_list(frame, contourss, all_freeman_chaincodes,roi_x, roi_y)\n",
        "                print(\"K-Means Labels:\", kmeans_labels)\n",
        "\n",
        "def detect_features(frame_gray, trajectories, lk_params,img):\n",
        "    img0, img1 = prev_gray, frame_gray\n",
        "    p0 = np.float32([trajectory[-1] for trajectory in trajectories]).reshape(-1, 1, 2)\n",
        "    p1, _st, _err = cv2.calcOpticalFlowPyrLK(img0, img1, p0, None, **lk_params)\n",
        "    p0r, _st, _err = cv2.calcOpticalFlowPyrLK(img1, img0, p1, None, **lk_params)\n",
        "    d = abs(p0 - p0r).reshape(-1, 2).max(-1)\n",
        "    good = d < 1\n",
        "\n",
        "    new_trajectories = []\n",
        "\n",
        "    # Obtener todas las trayectorias\n",
        "    for trajectory, (x, y), good_flag in zip(trajectories, p1.reshape(-1, 2), good):\n",
        "        if not good_flag:\n",
        "            continue\n",
        "        trajectory.append((x, y))\n",
        "        if len(trajectory) > trajectory_len:\n",
        "            del trajectory[0]\n",
        "        new_trajectories.append(trajectory)\n",
        "        # Punto más recientemente detectado\n",
        "        cv2.circle(img, (int(x), int(y)), 2, (0, 0, 255), -1)\n",
        "\n",
        "    trajectories = new_trajectories\n",
        "\n",
        "    return  trajectories\n",
        "\n",
        "def get_freeman_chaincode(contour):\n",
        "    chain_code = []\n",
        "    direction_map = [0, 1, 2, 3, 4, 5, 6, 7]\n",
        "\n",
        "    for i in range(1, len(contour)):\n",
        "        delta_x = contour[i][0][0] - contour[i - 1][0][0]\n",
        "        delta_y = contour[i][0][1] - contour[i - 1][0][1]\n",
        "\n",
        "        # Determinar la dirección del movimiento\n",
        "        direction = (delta_x > 0) + (delta_y > 0) * 2 + (delta_x < 0) * 4 + (delta_y < 0) * 6\n",
        "\n",
        "        try:\n",
        "            chain_code.append(direction_map.index(direction))\n",
        "        except ValueError:\n",
        "            # Si la dirección no está en la lista, manejar la excepción\n",
        "            pass\n",
        "\n",
        "    return chain_code\n",
        "\n",
        "def extract_freeman_from_contours(contours):\n",
        "    freeman_chaincodes = []\n",
        "\n",
        "    for contour in contours:\n",
        "        freeman_chaincode = get_freeman_chaincode(contour)\n",
        "        freeman_chaincodes.append(freeman_chaincode)\n",
        "\n",
        "    return freeman_chaincodes\n",
        "\n",
        "\n",
        "trajectory_len = 40\n",
        "detect_interval = 5\n",
        "trajectories = []\n",
        "frame_idx = 0\n",
        "\n",
        "video_path = 'video333.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "# Después de abrir el video, antes de entrar al bucle while\n",
        "width = 1366  # El ancho deseado\n",
        "height = 768  # La altura deseada\n",
        "\n",
        "# Asegúrate de que el video tenga el tamaño deseado\n",
        "cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
        "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
        "\n",
        "# Diccionario para realizar un seguimiento de los contornos y sus colores\n",
        "contours_dict = {}\n",
        "\n",
        "# Umbral inferior y superior para el área del contorno\n",
        "min_contour_area = 600\n",
        "max_contour_area = 7000\n",
        "\n",
        "while True:\n",
        "    # Tiempo de inicio para calcular los FPS\n",
        "    start = time.time()\n",
        "    suc, frame = cap.read()\n",
        "\n",
        "    if not suc or frame is None:\n",
        "        break  # Si no se puede leer el siguiente cuadro, sal del bucle\n",
        "\n",
        "    lk_params, feature_params = initialize_params()\n",
        "\n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    img = frame.copy()\n",
        "\n",
        "    #  Método  Lucas-Kanade\n",
        "    if len(trajectories) > 0:\n",
        "        trajectories = detect_features(frame_gray, trajectories, lk_params, img)\n",
        "        process_roi(frame, trajectories, min_contour_area, max_contour_area, contours_dict, img)\n",
        "\n",
        "    # Intervalo de actualización: cuando actualizar y detectar nuevas características\n",
        "    if frame_idx % detect_interval == 0:\n",
        "        mask = np.zeros_like(frame_gray)\n",
        "        mask[:] = 255\n",
        "\n",
        "        # Último punto en la trayectoria más reciente\n",
        "        for x, y in [np.int32(trajectory[-1]) for trajectory in trajectories]:\n",
        "            cv2.circle(mask, (x, y), 5, 0, -1)\n",
        "\n",
        "        # Detectar las buenas características para seguir\n",
        "        p = cv2.goodFeaturesToTrack(frame_gray, mask=mask, **feature_params)\n",
        "        if p is not None:\n",
        "            # Si se pueden seguir buenas características, agregarlas a las trayectorias\n",
        "            for x, y in np.float32(p).reshape(-1, 2):\n",
        "                trajectories.append([(x, y)])\n",
        "\n",
        "    frame_idx += 1\n",
        "    prev_gray = frame_gray\n",
        "\n",
        "    # End time\n",
        "    end = time.time()\n",
        "    # Calcular los FPS (cuadros por segundo) para la detección del cuadro actual\n",
        "    fps = 1 / (end - start)\n",
        "\n",
        "    # Mostrar resultados\n",
        "    # Redimensiona la imagen para mostrarla con el tamaño deseado\n",
        "    img_resized = cv2.resize(img, (width, height))\n",
        "\n",
        "    # cv2.putText(img, f\"{fps:.2f} FPS\", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "    cv2.imshow('Optical Flow', img_resized)\n",
        "    # cv2.imshow('Mask', mask)\n",
        "\n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import time\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Diccionario para almacenar colores únicos por clúster\n",
        "cluster_colors = {}\n",
        "\n",
        "def get_random_color(cluster):\n",
        "    # Verificar si ya se asignó un color para este clúster\n",
        "    if cluster not in cluster_colors:\n",
        "        # Si no se ha asignado, generar un color aleatorio\n",
        "        cluster_colors[cluster] = tuple(map(int, np.random.randint(0, 256, 3)))\n",
        "    return cluster_colors[cluster]\n",
        "\n",
        "def elbow_method(data, max_clusters=10):\n",
        "    distortions = []\n",
        "    n_samples = len(data)\n",
        "\n",
        "    for i in range(1, min(max_clusters, n_samples) + 1):\n",
        "        kmeans = KMeans(n_clusters=i, random_state=0)\n",
        "        kmeans.fit(data)\n",
        "        distortions.append(kmeans.inertia_)\n",
        "\n",
        "    # Calcular la derivada segunda de la curva de distorsión\n",
        "    acceleration = np.diff(np.diff(distortions))\n",
        "\n",
        "    # Encontrar el índice donde la aceleración es máxima\n",
        "    optimal_k_index = np.argmax(acceleration) + 2  # Sumar 2 para compensar la doble diferenciación\n",
        "\n",
        "    # Graficar la curva de distorsión y resaltar el punto óptimo\n",
        "    plt.plot(range(1, min(max_clusters, n_samples) + 1), distortions, marker='o')\n",
        "    plt.scatter(optimal_k_index, distortions[optimal_k_index - 1], c='red', label='Optimal k')\n",
        "    plt.title('Elbow Method for Optimal k')\n",
        "    plt.xlabel('Number of Clusters')\n",
        "    plt.ylabel('Distortion')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Devolver el número óptimo de clústeres\n",
        "    return optimal_k_index\n",
        "\n",
        "def apply_kmeans_to_freeman_list(img, contours, freeman_chaincodes,roi_x, roi_y):\n",
        "    if not freeman_chaincodes:\n",
        "        print(\"No hay datos para aplicar K-Means.\")\n",
        "        return []\n",
        "\n",
        "    # Obtener características de las cadenas de Freeman\n",
        "    def get_freeman_features(chain_code):\n",
        "        length = len(chain_code)\n",
        "        direction_changes = sum(1 for a, b in zip(chain_code, chain_code[1:]) if a != b)\n",
        "        return length, direction_changes\n",
        "\n",
        "    # Obtener características para cada cadena de Freeman\n",
        "    features = [get_freeman_features(chain_code) for chain_code in freeman_chaincodes]\n",
        "    features_array = np.array(features)\n",
        "\n",
        "    if features_array.ndim == 1:\n",
        "        # Si es un array 1D, redimensiona a 2D\n",
        "        features_array = features_array.reshape(-1, 1)\n",
        "\n",
        "    # Aplicar el método del codo para determinar el número óptimo de clústeres\n",
        "    optimal_k = elbow_method(features_array, max_clusters=10)\n",
        "    print(optimal_k)\n",
        "\n",
        "    # Aplicar k-medias con el número óptimo de clústeres\n",
        "    kmeans = KMeans(n_clusters=optimal_k, random_state=0)\n",
        "    kmeans.fit(features_array)\n",
        "\n",
        "    # Obtener etiquetas para cada cadena de Freeman\n",
        "    labels = kmeans.labels_\n",
        "\n",
        "    # Visualizar en un gráfico de dispersión\n",
        "    lengths, changes = zip(*[get_freeman_features(chain_code) for chain_code in freeman_chaincodes])\n",
        "    plt.scatter(lengths, changes, c=labels, cmap='viridis', marker='o', edgecolors='k', label='Data Points')\n",
        "    plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c='red', marker='x', s=200,\n",
        "                label='Centroids')\n",
        "    plt.title('K-Means Clustering of Freeman Chain Codes with Centroids')\n",
        "    plt.xlabel('Length of Chain Code')\n",
        "    plt.ylabel('Number of Direction Changes')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Crear una imagen para visualizar elementos de cada clúster en el frame\n",
        "    clustered_frame = img.copy()\n",
        "\n",
        "    # Encontrar contornos en la máscara\n",
        "    for i, contour in enumerate(contours):\n",
        "        cluster_color = get_random_color(labels[i])\n",
        "        cv2.drawContours(clustered_frame, [contour], -1, (0, 255, 0), 2, offset=(roi_x, roi_y))\n",
        "        cv2.drawContours(clustered_frame, [contour], -1, cluster_color, -1, offset=(roi_x, roi_y))\n",
        "\n",
        "\n",
        "    img_resized = cv2.resize(clustered_frame, (width, height))\n",
        "    cv2.imshow(\"Clustered Objects\",img_resized )\n",
        "    cv2.waitKey(0)  # Esperar hasta que se presione una tecla para cerrar la ventana\n",
        "\n",
        "    return labels\n",
        "\n",
        "def initialize_params():\n",
        "    lk_params = dict(winSize=(30, 30),\n",
        "                 maxLevel=5,\n",
        "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 15, 0.01))\n",
        "\n",
        "    feature_params = dict(maxCorners=100,\n",
        "                      qualityLevel=0.01,\n",
        "                      minDistance=10,\n",
        "                      blockSize=7)\n",
        "    return lk_params, feature_params\n",
        "\n",
        "def process_roi(frame, trajectories, min_contour_area, max_contour_area, contours_dict, img):\n",
        "    if len(trajectories) > 0:\n",
        "        all_points = np.concatenate([np.int32(trajectory) for trajectory in trajectories])\n",
        "        x, y, w, h = cv2.boundingRect(all_points)\n",
        "\n",
        "        if 0 <= y < frame.shape[0] and 0 <= x < frame.shape[1] and h > 0 and w > 0:\n",
        "            roi = frame[y:y + h, x:x + w]\n",
        "            roi_x, roi_y = x, y  # Agrega estas líneas\n",
        "\n",
        "            if roi.size != 0:\n",
        "                roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
        "                _, thresh = cv2.threshold(roi_gray, 127, 255, 0)\n",
        "                contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "                contourss, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "                filtered_contours = [cnt for cnt in contours if min_contour_area < cv2.contourArea(cnt) < max_contour_area]\n",
        "\n",
        "                for trajectory in trajectories:\n",
        "                    for x, y in np.int32(trajectory):\n",
        "                        # Dibujar punto\n",
        "                        cv2.circle(img, (x, y), 1, (255, 0, 255), -1)\n",
        "\n",
        "                for contour in filtered_contours:\n",
        "                    # No agregar x e y aquí\n",
        "                    x, y, w, h = cv2.boundingRect(contour)\n",
        "                    cv2.rectangle(img, (x + roi_x, y + roi_y), (x + w + roi_x, y + h + roi_y), (255, 0, 0), 2)\n",
        "\n",
        "                    contour_id = id(contour)\n",
        "\n",
        "                    if contour_id not in contours_dict:\n",
        "                        color = tuple(np.random.randint(0, 255, 3).tolist())\n",
        "                        contours_dict[contour_id] = color\n",
        "                    else:\n",
        "                        color = contours_dict[contour_id]\n",
        "\n",
        "                    # No agregar x e y aquí\n",
        "                    cv2.drawContours(img, [contour + (roi_x, roi_y)], -1, color, 2)\n",
        "\n",
        "                all_freeman_chaincodes = extract_freeman_from_contours(contourss)\n",
        "                kmeans_labels = apply_kmeans_to_freeman_list(frame, contourss, all_freeman_chaincodes,roi_x, roi_y)\n",
        "                print(\"K-Means Labels:\", kmeans_labels)\n",
        "\n",
        "def detect_features(frame_gray, trajectories, lk_params,img):\n",
        "    img0, img1 = prev_gray, frame_gray\n",
        "    p0 = np.float32([trajectory[-1] for trajectory in trajectories]).reshape(-1, 1, 2)\n",
        "    p1, _st, _err = cv2.calcOpticalFlowPyrLK(img0, img1, p0, None, **lk_params)\n",
        "    p0r, _st, _err = cv2.calcOpticalFlowPyrLK(img1, img0, p1, None, **lk_params)\n",
        "    d = abs(p0 - p0r).reshape(-1, 2).max(-1)\n",
        "    good = d < 1\n",
        "\n",
        "    new_trajectories = []\n",
        "\n",
        "    # Obtener todas las trayectorias\n",
        "    for trajectory, (x, y), good_flag in zip(trajectories, p1.reshape(-1, 2), good):\n",
        "        if not good_flag:\n",
        "            continue\n",
        "        trajectory.append((x, y))\n",
        "        if len(trajectory) > trajectory_len:\n",
        "            del trajectory[0]\n",
        "        new_trajectories.append(trajectory)\n",
        "        # Punto más recientemente detectado\n",
        "        cv2.circle(img, (int(x), int(y)), 2, (0, 0, 255), -1)\n",
        "\n",
        "    trajectories = new_trajectories\n",
        "\n",
        "    return  trajectories\n",
        "\n",
        "def get_freeman_chaincode(contour):\n",
        "    chain_code = []\n",
        "    direction_map = [0, 1, 2, 3, 4, 5, 6, 7]\n",
        "\n",
        "    for i in range(1, len(contour)):\n",
        "        delta_x = contour[i][0][0] - contour[i - 1][0][0]\n",
        "        delta_y = contour[i][0][1] - contour[i - 1][0][1]\n",
        "\n",
        "        # Determinar la dirección del movimiento\n",
        "        direction = (delta_x > 0) + (delta_y > 0) * 2 + (delta_x < 0) * 4 + (delta_y < 0) * 6\n",
        "\n",
        "        try:\n",
        "            chain_code.append(direction_map.index(direction))\n",
        "        except ValueError:\n",
        "            # Si la dirección no está en la lista, manejar la excepción\n",
        "            pass\n",
        "\n",
        "    return chain_code\n",
        "\n",
        "def extract_freeman_from_contours(contours):\n",
        "    freeman_chaincodes = []\n",
        "\n",
        "    for contour in contours:\n",
        "        freeman_chaincode = get_freeman_chaincode(contour)\n",
        "        freeman_chaincodes.append(freeman_chaincode)\n",
        "\n",
        "    return freeman_chaincodes\n",
        "\n",
        "\n",
        "trajectory_len = 40\n",
        "detect_interval = 5\n",
        "trajectories = []\n",
        "frame_idx = 0\n",
        "\n",
        "video_path = 'car.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "# Después de abrir el video, antes de entrar al bucle while\n",
        "width = 1366  # El ancho deseado\n",
        "height = 768  # La altura deseada\n",
        "\n",
        "# Asegúrate de que el video tenga el tamaño deseado\n",
        "cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
        "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
        "\n",
        "# Diccionario para realizar un seguimiento de los contornos y sus colores\n",
        "contours_dict = {}\n",
        "\n",
        "# Umbral inferior y superior para el área del contorno\n",
        "min_contour_area = 600\n",
        "max_contour_area = 7000\n",
        "\n",
        "while True:\n",
        "    # Tiempo de inicio para calcular los FPS\n",
        "    start = time.time()\n",
        "    suc, frame = cap.read()\n",
        "\n",
        "    if not suc or frame is None:\n",
        "        break  # Si no se puede leer el siguiente cuadro, sal del bucle\n",
        "\n",
        "    lk_params, feature_params = initialize_params()\n",
        "\n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    img = frame.copy()\n",
        "\n",
        "    #  Método  Lucas-Kanade\n",
        "    if len(trajectories) > 0:\n",
        "        trajectories = detect_features(frame_gray, trajectories, lk_params, img)\n",
        "        process_roi(frame, trajectories, min_contour_area, max_contour_area, contours_dict, img)\n",
        "\n",
        "    # Intervalo de actualización: cuando actualizar y detectar nuevas características\n",
        "    if frame_idx % detect_interval == 0:\n",
        "        mask = np.zeros_like(frame_gray)\n",
        "        mask[:] = 255\n",
        "\n",
        "        # Último punto en la trayectoria más reciente\n",
        "        for x, y in [np.int32(trajectory[-1]) for trajectory in trajectories]:\n",
        "            cv2.circle(mask, (x, y), 5, 0, -1)\n",
        "\n",
        "        # Detectar las buenas características para seguir\n",
        "        p = cv2.goodFeaturesToTrack(frame_gray, mask=mask, **feature_params)\n",
        "        if p is not None:\n",
        "            # Si se pueden seguir buenas características, agregarlas a las trayectorias\n",
        "            for x, y in np.float32(p).reshape(-1, 2):\n",
        "                trajectories.append([(x, y)])\n",
        "\n",
        "    frame_idx += 1\n",
        "    prev_gray = frame_gray\n",
        "\n",
        "    # End time\n",
        "    end = time.time()\n",
        "    # Calcular los FPS (cuadros por segundo) para la detección del cuadro actual\n",
        "    fps = 1 / (end - start)\n",
        "\n",
        "    # Mostrar resultados\n",
        "    # Redimensiona la imagen para mostrarla con el tamaño deseado\n",
        "    img_resized = cv2.resize(img, (width, height))\n",
        "\n",
        "    # cv2.putText(img, f\"{fps:.2f} FPS\", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "    cv2.imshow('Optical Flow', img_resized)\n",
        "    # cv2.imshow('Mask', mask)\n",
        "\n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "VrJ13s-Q_Ohm",
        "outputId": "64c7710a-e5f8-496b-86eb-a68e41e82aca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "DisabledFunctionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDisabledFunctionError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c070f40a27bc>\u001b[0m in \u001b[0;36m<cell line: 230>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;31m# cv2.putText(img, f\"{fps:.2f} FPS\", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Optical Flow'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_resized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;31m# cv2.imshow('Mask', mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_import_hooks/_cv2.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mDisabledFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDisabledFunctionError\u001b[0m: cv2.imshow() is disabled in Colab, because it causes Jupyter sessions\nto crash; see https://github.com/jupyter/notebook/issues/3935.\nAs a substitution, consider using\n  from google.colab.patches import cv2_imshow\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_snippet",
                "actionText": "Search Snippets for cv2.imshow",
                "snippetFilter": "cv2.imshow"
              }
            ]
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}